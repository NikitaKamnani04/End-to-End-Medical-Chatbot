{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\End-to-End-Medical-Chatbot\\\\research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\End-to-End-Medical-Chatbot'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data from PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_file(data='C:\\End-to-End-Medical-Chatbot\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into Text Chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 39994\n"
     ]
    }
   ],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "print(\"Length of Text Chunks\",len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the Embeddings from Hugging Face\n",
    "# def download_hugging_face_embeddings():\n",
    "#     embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "#     return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings=download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.48.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikita kamnani\\.conda\\envs\\medibot\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the Embeddings from Hugging Face\n",
    "def download_hugging_face_embeddings():\n",
    "     embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "     return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikita kamnani\\AppData\\Local\\Temp\\ipykernel_23376\\620568460.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embeddings= download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Length\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getenv(\"PINECONE_API_KEY\"))\n",
    "# print(os.getenv(\"COHERE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index: medicalbot\n",
      "Error creating index: (409)\n",
      "Reason: Conflict\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-07', 'X-Cloud-Trace-Context': '50f7c25045585595602b8a0edfd8cd35', 'Date': 'Tue, 18 Feb 2025 10:58:47 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec, PineconeApiException\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "# List existing indexes\n",
    "existing_indexes = pc.list_indexes()\n",
    "\n",
    "# Check if the index already exists\n",
    "if index_name in existing_indexes:\n",
    "    print(f\"Index '{index_name}' already exists. Skipping creation.\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Creating index: {index_name}\")\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,  # Replace with your model dimensions\n",
    "            metric=\"cosine\",  # Replace with your model metric\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  # Specify your cloud and region\n",
    "        )\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    except PineconeApiException as e:\n",
    "        print(f\"Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\n",
    "os.environ[\"COHERE_API_KEY\"]=COHERE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed each chunk and upsert the embeddings into your Pinecone Index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing Index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "#Embed each chunk and upsert the embeddings into your Pinecone Index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x26f73da3d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=retriever.invoke(\"What is Acne?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0990dd7f-f77d-4b4a-a83a-bc08380afb60', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'C:\\\\End-to-End-Medical-Chatbot\\\\Data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'),\n",
       " Document(id='cff8bb46-097c-46b4-83f0-96019496b801', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'C:\\\\End-to-End-Medical-Chatbot\\\\Data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne'),\n",
       " Document(id='e229d4ab-557c-4ada-97f3-955f6770ea65', metadata={'creationdate': '2006-10-16T20:19:33+02:00', 'creator': 'Adobe Acrobat 6.0', 'moddate': '2006-10-16T22:03:45+02:00', 'page': 55.0, 'page_label': '26', 'producer': 'PDFlib+PDI 6.0.3 (SunOS)', 'source': 'C:\\\\End-to-End-Medical-Chatbot\\\\Data\\\\The-Gale-Encyclopedia-of-Medicine-3rd-Edition-staibabussalamsula.ac_.id_.pdf', 'total_pages': 4505.0}, page_content='Researchers, Inc. Reproduced by permission.)\\n26 GALE ENCYCLOPEDIA OF MEDICINE\\nAcne')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As i want defination so process is \n",
    "import os\n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# Set API Key in environment variables\n",
    "os.environ[\"COHERE_API_KEY\"] = \"dPlXVSswiGgW9sudLfu1z8lPAu68oGV6OMMXDSHx\"\n",
    "\n",
    "# Initialize the Cohere LLM\n",
    "llm = Cohere(temperature=0.4, max_tokens=500)\n",
    "\n",
    "# Example usage\n",
    "# response = llm.invoke(\"What is Acne?\")\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer the question \"\n",
    "    \"If you don't know the answer, say that you don't know\"\n",
    "    \"use three sentences maximum and keep the answer concise\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain= create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Acne is a chronic skin disease involving blockage and inflammation of the sebaceous glands and hair follicles. It is characterized by whiteheads, blackheads, and inflamed lesions. In mild cases, acne usually resolves itself, but it can lead to scarring in more severe cases. \n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What is Acne?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
